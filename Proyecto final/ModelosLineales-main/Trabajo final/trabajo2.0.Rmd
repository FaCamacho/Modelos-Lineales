---
title: "Trabajo final"
author: "matias"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}

library(tidyverse)
library(readxl)
library(here)
library(mixlm)
library(gridExtra)
library(car)
library(skedastic)
library(qqplotr)
library(tseries)
library(emmeans)
library(boot) 






```

## Metodologia e introduccion 

El objetivo de este trabajo es implementar las tecnicas de analisis  estudiadas en el curso de Modelos Lineales, en partiuclar, el modelo de regresion multiple.

En una primera instancia, se procede a hacer un analisis explotatorio de los datos. 
Luego pasamos a una primera etapa de diagnostico, donde  se procede a estudiar  el supuesto de la multicolinealidad aproximiada, en el cual nos sirve para quedarnos con las variables explicativas siguiendo el criterio de Vif<5.

En la siguiente etapa, seleccionamos 3 posibles modelos, luego estudiamos el supuesto de homoscedasticidad en los residuos como tambien el test de normalidad 

En una tercera instancia, se hizo un analisis ANOVA y ANCOVA. 

Para finalizar, se usaron tecnicas como cross validation y leave-one-out para evalular los 3 modelos. 




## Descripcion de la base

Para este informe se trabajo con una base de peces. La misma consta con 158 observaciones de peces y con las siguientes variables:

La base de datos contiene información respecto de las siguientes variables:
\begin{itemize}
  \item Especie: Nombre de la especie del pescado
  \item Peso_gr: Peso del pescado en gramos
  \item LLongitud1: Longitud vertical en centímetros
  \item Longitud2: Longitud diagonal en centímetros
  \item Longitud3: Longitud transversal en centímetros
  \item Altura_cm: Altura en centímetros
  \item Ancho_cm: Ancho diagonal en centímetros
\end{itemize}

A efectos de tener un primer acercamiento con la estructura de los datos, se obtienen algunas estadisticas descripitvas, como la correlacion entre las variables cuantitativas   y un diagrama de caja para visualizar el peso en relacion a cada especie 


```{r}
#Cargar los datos
colores <- c("#003f5c", "#7a5195", "#ef5675", "#ffa600")

datos = biometria_peces


```

## Aalisis exploratorio de los datos

```{r}


str(datos)

summary(datos)

datos = datos %>%  mutate(Peso_gr = as.numeric(Peso_gr),Especie = as.factor(Especie) ) 


str(datos)

summary(datos) #Hay un pez con peso 0 gr

datos <- datos %>% filter(.,Peso_gr > 0)

summary(datos) #Deberíamos quitar el de 5.9 gr

datos <- datos %>% filter(.,Peso_gr > 5.9)

summary(datos)

cuanti = datos %>%  select(2:7) 


matriz_correlacion <- cor(cuanti) 

 p =ggcorrplot::ggcorrplot(
        matriz_correlacion,
        method = "circle", 
        type = "upper",
        outline.col = "black",
        ggtheme = ggplot2::theme_gray,
        legend.title = "Correlacion",
        colors = c(tail(colores, 1), "#ffffff", colores[1])
      ) + 
      guides(
        fill = guide_colorbar(barheight = grid::unit(0.75, "npc"))
      )
 
 p


```


#Análisis gráfico


```{r}


longitud <- ggplot(datos, aes(x = log(Longitud1), y = log(Peso_gr))) + 
  geom_point(alpha=0.5,size=2)+
  theme_bw() +
  xlab('Longitud') +
  ylab('Peso')


ancho <- ggplot(datos, aes(x = log(Ancho_cm), y = log(Peso_gr))) + 
  geom_point(alpha=0.5,size=2)+
  theme_bw() +
  xlab('Ancho') +
  ylab('Peso')

altura <- ggplot(datos, aes(x = log(Altura_cm), y = log(Peso_gr))) + 
  geom_point(alpha=0.5,size=2)+
  theme_bw() +
  xlab('Alto') +
  ylab('Peso')

longitud_especie <- ggplot(datos, aes(x = log(Longitud1), y = log(Peso_gr), color=Especie)) + 
  geom_point(alpha=0.5,size=2)+
  theme_bw() +
  xlab('Longitud') +
  ylab('Peso')


ancho_especie <- ggplot(datos, aes(x = log(Ancho_cm), y = log(Peso_gr), color=Especie)) + 
  geom_point(alpha=0.5,size=2)+
  theme_bw() +
  xlab('Ancho') +
  ylab('Peso')

altura_especie <- ggplot(datos, aes(x = log(Altura_cm), y = log(Peso_gr), color=Especie)) + 
  geom_point(alpha=0.5,size=2)+
  theme_bw() +
  xlab('Alto') +
  ylab('Peso')







grid.arrange(longitud_especie
             ,ancho_especie
             ,altura_especie,
             ncol=1,nrow=3)

```


## Análisis de supuestos sobre modelos lineales
#Multicolinealidad
```{r}

#Analizando multicolinealidad


vif(lm(Peso_gr~ .-Especie, data = datos))


#Quitando Long2

vif(lm(Peso_gr~ .-Especie-Longitud2, data = datos))

#Quitando Long3

vif(lm(Peso_gr~ .-Especie-Longitud2-Longitud3, data = datos))

#Variables seleccionadas -> "Longitud1" , "Altura_cm" , "Ancho_cm"



```

##Modelos



## Modelo 1 

Como ya se menciono,el primer modelo estimado consiste en la regresion de la variable peso con las variables explicativas que fueron seleccionadas en el paso de multicolinealidad.
El modelo queda esepecificado como:

$$peso_{i}=  \beta_0 +\ \beta_1Longitud1_{i} + \beta_2Altura_{i}\ +\ beta_3Ancho_{i}\ +\ \epsilon_{i}$$


```{r}


modelo <- lm(Peso_gr~ Longitud1+Altura_cm+Ancho_cm, data = datos)

summary(modelo)

```




## Significacion individual

Para cada uno de las variables explicativas se realiza la siguiente prueba de hipotesis:

$$H_0) B_{i} = 0\ vs\ H_1) B_{i} \neq 0$$

Con region critica:  (poner la region critica)


poner el estadistico t 


Siguiendo el criterio del p_valor, la evidencia empirica sugiere que las variables  Longitud1 y Altura en centimetros son individualmente significativas para explicar el peos del pez a un nivel del5%.



## Signficacion global del modelo

Siguiendo el criterio del p_valor, a un nivel del 5%, la evidencia empirica sugiere que el modelo es globalmente significativo. Esto implica que, dada la evidencia empirica con la que se cuenta, no es posible rechazar la hipotesis de que las variables explicativas usadas no contribuyen a explicar el peso del pez.


## Diagnostico del modelo

##Homoscedasticidad 

En una primera instancia, se opto por recurrir  a un analisis visual de los residuos externamente estudientizados del modelo. 
A continuacion vemos el grafico de los residuos en el eje de las ordenadas 
Con un $\alpha=0.05$ rechazamos la hipotesis nula, por lo que podemos afirmar que no hay homoscedasticidad.


```{r}
datos$r_i <- residuals(modelo)  

# residuos

datos$t_i <- rstudent(modelo) #studentizados EXTERNAMENTE 

datos$pred <- fitted(modelo)

# H0) E(eps^2_i) = sigma^2
# H1) E(eps^2_i) = sigma^2 * h(X_1, X_2, ..., X_k)



breusch_pagan(modelo) # Rechazo H0) con p-valor  del 0.01%


x0 = ggplot(datos, aes(x = pred, y = t_i)) + 
  geom_point(color = "red",alpha=0.5,size=1)+
  xlab('Predichos') +
  ylab('Residuos') +
 geom_abline(slope=0, intercept=c(-1,1), linetype="dashed",color="blue")+
  geom_abline(slope = 0, intercept = 0,color="blue")   +theme_bw()




grafico = function(variable) {
  ggplot(datos,aes(x=.data[[variable]],y=.data[["t_i"]])) +
    geom_point(alpha=0.5,size=1,color = "red") +
  
    labs(x = variable, y = "t_i") + 
 geom_abline(slope=0, intercept=c(-1,1), linetype="dashed",color="blue") +  geom_abline(slope = 0, intercept = 0,color="blue")   +theme_bw()
}




x1=grafico("Longitud1")
x4=grafico("Altura_cm")
x5= grafico("Ancho_cm")


grid.arrange(x0,x1,x4,x5,ncol=2,nrow=2)

#grid.arrange(crPlot(modelo,"Longitud1"),crPlot(modelo,"Altura_cm"),crPlot(modelo,"Ancho_cm"),ncol=3,nrow=1)

plot(modelo)



```
## Normalidad 

El histograma  de los residuos estandarizados parece no parecerse a  una distribucion  normal en los residuos.
Ademas, los test de normalidad de Shapiro-Wilk y Jarque-Bera, segun el criterio del p_valor y para un $\alpha=0.5$ se rechaza la hipotesis nula de normalidad de los residuos.

```{r}
n <- nrow(datos)

z_i <- qnorm(seq(n)/(n + 1))

qq <- data.frame(teoricos = z_i,empiricos = sort(datos$t_i))




# PRUEBA DE HIPOTESIS
# H0) Los errores son normales
# H1) Los errores NO son normales


shapiro.test(datos$t_i) #Rechazo H0) con un alpha al 5%
tseries::jarque.bera.test(datos$t_i) #Rechazo H0) con un p-valor de 5%


ggplot(qq, aes(x = empiricos, y=..density..)) +
  geom_histogram(bins=10) +  
      theme(axis.title.y=element_blank(),
            axis.ticks.x=element_blank(),
            axis.ticks.y=element_blank(),
            axis.title.x=element_text(face="bold", size=12),
            plot.title=element_text(size=16, face="bold", hjust=0.5)) +
  xlab('Residuos studentizados')
```



modelo_ajustado <- lm(log(Peso_gr) ~ (Longitud1)+(Altura_cm)+(Ancho_cm), data = datos)



modelo_ajustado2 <- lm(log(Peso_gr) ~ log(Longitud1)+log(Altura_cm)+log(Ancho_cm), data = datos)







## Homoscedasticidad de "Modelo_ajustado2"

```{r}

datos$r_i <- residuals(modelo_ajustado2)  

# residuos

datos$t_i <- rstudent(modelo_ajustado2) #studentizados EXTERNAMENTE 

datos$pred <- fitted(modelo_ajustado2)

# H0) E(eps^2_i) = sigma^2
# H1) E(eps^2_i) = sigma^2 * h(X_1, X_2, ..., X_k)



breusch_pagan(modelo_ajustado2) #No Rechazo H0) con p-valor de 0.73


ggplot(datos, aes(x = pred, y = t_i)) + 
  geom_point(color = "red",alpha=0.5,size=1)+
  xlab('Predichos') +
  ylab('Residuos') +
 geom_abline(slope=0, intercept=c(-1,1), linetype="dashed",color="blue")+
  geom_abline(slope = 0, intercept = 0,color="blue")   +theme_bw()



#grid.arrange(crPlot(modelo,"Longitud1"),crPlot(modelo,"Altura_cm"),crPlot(modelo,"Ancho_cm"),ncol=3,nrow=1)

plot(modelo_ajustado2)




```

##Normalidad

```{r}

n <- nrow(datos)

z_i <- qnorm(seq(n)/(n + 1))

qq <- data.frame(teoricos = z_i,empiricos = sort(datos$t_i))

ggplot(qq, aes(x = teoricos, y = empiricos)) +
  geom_point() +
  xlab('Cuantiles teoricos') +
  ylab('Cuantiles empiricos') +
  geom_abline(slope = 1, intercept = 0, col = 2, size = 1.5)


# PRUEBA DE HIPOTESIS
# H0) Los errores son normales
# H1) Los errores NO son normales


shapiro.test(datos$t_i) #Rechazo H0) con un p-valor de 0.0049
tseries::jarque.bera.test(datos$t_i) #Rechazo H0) con un p-valor de 1.794e-05
ks.test(datos$t_i, 'pnorm') #No Rechazo H0) con un p-valor de 0.5317

ggplot(qq, aes(x = empiricos, y=..density..)) +
  geom_histogram(breaks = seq(-3, 3, 1), col = 'white') +
  xlab('Residuos studentizados')
```



## Atípicos

```{r}

h_i <- influence(modelo_ajustado2)$hat
D_i <- cooks.distance(modelo_ajustado2)
df <- data.frame(i = 1:nrow(datos),
                 h_i = h_i,
                 D_i = D_i)

# Distancia de Cook
ggplot(df, aes(x = i, y = D_i)) +
  geom_point() +
  geom_segment(aes(x = i, xend = i, y = 0, yend = D_i)) +
  xlab('') +
  ylab(expression(D[i])) +
  geom_abline(slope = 0, intercept = 4/50, col = 2, linetype = 'dashed')

#hay algún atípico 

```


#evaluacion de modelo 

```{r}
 bic1 = BIC(modelo)
bic2= BIC(modelo_ajustado)
bic3 = BIC(modelo_ajustado2)
aic1 = AIC(modelo)
aic2=AIC(modelo_ajustado)
aic3= AIC(modelo_ajustado2)

summary(modelo)$adj.r.squared

summary(modelo_ajustado)$adj.r.squared

summary(modelo_ajustado2)$adj.r.squared




```
## ANOVA a 1 vía


```{r}


datos_especie <- datos %>%
  group_by(Especie) %>%
  summarise("media(peso)" = round(mean(Peso_gr),2),
            "desvio(peso)" = round(sd(Peso_gr),2),
            "min(peso)"=round(min(Peso_gr),2),
            "max(peso)"=round(max(Peso_gr),2))

datos_especie



mod1 <- lm(log(Peso_gr) ~ Especie, data = datos) #Modelo con "Peso ~ Especie"

mod0 <- lm(log(Peso_gr) ~ 1, data = datos) #Modelo con "Peso ~ 1"

anova(mod0, mod1)

#H0) m1 = m2 = ... = mJ
#H1) No H0)

#p-value: 2.2e-16 de la prueba de significación global
# Rechazamos H0) y afirmamos que la especie es relevante para determinar el peso de un pez


#Ahora con el modelo completo

mod1 <- lm(log(Peso_gr) ~ log(Longitud1) + log(Ancho_cm) + log(Altura_cm) + Especie, data = datos) #Con especie


mod0 <- lm(log(Peso_gr) ~ log(Longitud1) + log(Ancho_cm) + log(Altura_cm) , data = datos) #Sin especie

Anova(mod1, mod0)

#Con un p-valor de 2.655e-06 la especie es significativa para el modelo



summary(lm((Peso_gr) ~ Especie + 0, data = datos))

#Vemos que para algunos peces la especie es relevante para determinar el peso mientras que para otras no
#Por ejemplo, para los Bream estamos en el primer caso mientras que para los Smelt en el segundo


ggplot(datos,aes(x=Especie,y=log(Peso_gr),fill=Especie)) + geom_boxplot() +xlab('Peso') + 
  ylab('Longitud')

ggplot(datos, aes(x = log(Peso_gr), y = log(Longitud1), fill = Especie)) +
  geom_boxplot() +
  xlab('Peso') + 
  ylab('Longitud') +
  theme_bw()



```


```{r}
# residuos

datos$t_i <- rstudent(mod1) #studentizados EXTERNAMENTE 

datos$pred <- fitted(mod1)

# H0) E(eps^2_i) = sigma^2
# H1) E(eps^2_i) = sigma^2 * h(X_1, X_2, ..., X_k)

breusch_pagan(mod1) #No Rechazo H0) con p-valor 0.92

# Normalidad

n <- nrow(datos)

z_i <- qnorm(seq(n)/(n + 1))

qq <- data.frame(teoricos = z_i,empiricos = sort(datos$t_i))

ggplot(qq, aes(x = teoricos, y = empiricos)) +
  geom_point() +
  xlab('Cuantiles teoricos') +
  ylab('Cuantiles empiricos') +
  geom_abline(slope = 1, intercept = 0, col = 2, size = 1.5)


# PRUEBA DE HIPOTESIS
# H0) Los errores son normales
# H1) Los errores NO son normales


shapiro.test(datos$t_i) #Rechazo H0) con p-value = 0.001005
tseries::jarque.bera.test(datos$t_i) #Rechazo H0) con p-value = 4.169e-09
ks.test(datos$t_i, 'pnorm') #No Rechazo H0) con p-value = 0.8776

ggplot(qq, aes(x = empiricos, y=..density..)) +
  geom_histogram(breaks = seq(-3, 3, 1), col = 'white') +
  xlab('Residuos studentizados')



###Supuestos de ANCOVA

## Supuesto de correlación

with(datos,cor(Peso_gr,Longitud1))
# Correlacion fuerte de 0.92


crPlot(mod1, variable = 'log(Longitud1)', pch = 16)

# Supuesto igualdad de pendientes
mod2 <- lm(log(Peso_gr)~ log(Longitud1) + Especie + log(Longitud1):Especie, data = datos)

#H0) b1 = b2 = ... = bJ
#H1) No H0)

anova(mod1, mod2) #No Rechazo H0)

# Supuesto la covariable NO afecta la media de cada especie
anova(lm(log(Longitud1) ~ Especie, data = datos))

#p-valor : < 2.2e-16
# Rechazo el supuesto de que la covariable NO afecta la medida de cada especie



ggplot(datos, aes(x = log(Peso_gr), y = log(Longitud1), col = Especie)) +
  geom_point() +
  xlab('Peso') + 
  ylab('Longitud') +
  theme_bw()+
  geom_smooth(method = 'lm', se =FALSE)

#Aquí vemos rectas notoriamente lineales, con las mismas pendientes y dispersión en torno a las rectas de regresión lineal

#Concluimos que la longitud como covariable no altera la capacidad explicativa de la especie.





```



## Ancova 

```{r}

#Modelo con Covariable Longitud

mod1 <- lm(log(Peso_gr) ~ log(Longitud1) + Especie, data = datos)

###Supuestos de linealidad

#Homosedasticidad

datos$r_i <- residuals(mod1)  



ggplot(datos, aes(x =log(Altura_cm), y = log(Peso_gr), color=Especie)) + 
  geom_point(alpha=0.5,size=2)+
  xlab('Altura_cm') +
  ylab('Peso')
```





```{r}

#Modelo con Covariable ANCHO

mod3 <- lm(log(Peso_gr) ~ log(Ancho_cm) + Especie  , data = datos)

###Supuestos de modelos lineales

#Linealidad

with(datos,cor(Peso_gr,Ancho_cm)) #Correlacion debil de 0.14

#plot(log(datos$Peso_gr), log(datos$Ancho_cm))

<<<<<<< HEAD
ggplot(datos, aes(x=log(Ancho_cm), y = log(Peso_gr))) + geom_point(size=2, alpha=0.5) + theme_bw()


#plot(lm(lm(log(Peso_gr) ~ log(Ancho_cm)  , data = datos)))
=======
# plot(lm(lm(log(Peso_gr) ~ log(Ancho_cm)  , data = datos)))
>>>>>>> ea9c9b45993af3b30853674649484042620593c8

#Homosedasticidad

datos$r_i <- residuals(mod3)  

# residuos

datos$t_i <- rstudent(mod3) #studentizados EXTERNAMENTE 

datos$pred <- fitted(mod3)

# H0) E(eps^2_i) = sigma^2
# H1) E(eps^2_i) = sigma^2 * h(X_1, X_2, ..., X_k)

breusch_pagan(mod3) #Rechazo H0) con p-valor 0.0001425355

# Normalidad

n <- nrow(datos)

z_i <- qnorm(seq(n)/(n + 1))

qq <- data.frame(teoricos = z_i,empiricos = sort(datos$t_i))

ggplot(qq, aes(x = teoricos, y = empiricos)) +
  geom_point() +
  xlab('Cuantiles teoricos') +
  ylab('Cuantiles empiricos') +
  geom_abline(slope = 1, intercept = 0, col = 2, size = 1.5)


# PRUEBA DE HIPOTESIS
# H0) Los errores son normales
# H1) Los errores NO son normales


shapiro.test(datos$t_i) #No echazo H0) p-value = 0.5116
tseries::jarque.bera.test(datos$t_i) #No Rechazo H0) p-value = 0.916
ks.test(datos$t_i, 'pnorm') #No Rechazo H0) 0.8489

ggplot(qq, aes(x = empiricos, y=..density..)) +
  geom_histogram(breaks = seq(-3, 3, 1), col = 'white') +
  xlab('Residuos studentizados')

###Supuestos de ANCOVA

## Supuesto de correlación

with(datos,cor(Peso_gr,Ancho_cm))
# Correlacion debil de 0.14


crPlot(mod3, variable = 'log(Ancho_cm)', pch = 16)

# Supuesto igualdad de pendientes
mod4 <- lm(Peso_gr~ Ancho_cm + Especie + Ancho_cm:Especie, data = datos)

#H0) b1 = b2 = ... = bJ
#H1) No H0)

anova(mod3, mod4) #Rechazo H0)

# Supuesto la covariable NO afecta la media de cada especie
anova(lm(Ancho_cm ~ Especie, data = datos))

#p-valor : < 2.2e-16
# Rechazo el supuesto de que la covariable Ancho NO afecta la medida de cada especie



ggplot(datos, aes(x = Peso_gr, y = Ancho_cm, col = Especie)) +
  geom_point() +
  xlab('Peso') + 
  ylab('Ancho') +
  theme_bw()+
  geom_smooth(method = 'lm', se =FALSE)

#Aquí vemos rectas lineales, con distintas pendientes y dispersión alejada de las rectas de regresión lineal en varios casos




```



```{r}

#Modelo con Covariable ALTURA

mod5 <- lm(log(Peso_gr) ~ log(Altura_cm) + Especie  , data = datos)

###Supuestos de modelos lineales

#Linealidad

with(datos,cor(Peso_gr,Altura_cm)) #Correlacion debil de 0.19

plot(log(datos$Peso_gr), log(datos$Altura_cm))


#Homosedasticidad

datos$r_i <- residuals(mod5)  

# residuos

datos$t_i <- rstudent(mod5) #studentizados EXTERNAMENTE 

datos$pred <- fitted(mod5)

# H0) E(eps^2_i) = sigma^2
# H1) E(eps^2_i) = sigma^2 * h(X_1, X_2, ..., X_k)

breusch_pagan(mod5) #Rechazo H0) con p-valor 3.463588e-05

# Normalidad

n <- nrow(datos)

z_i <- qnorm(seq(n)/(n + 1))

qq <- data.frame(teoricos = z_i,empiricos = sort(datos$t_i))

ggplot(qq, aes(x = teoricos, y = empiricos)) +
  geom_point() +
  xlab('Cuantiles teoricos') +
  ylab('Cuantiles empiricos') +
  geom_abline(slope = 1, intercept = 0, col = 2, size = 1.5)


# PRUEBA DE HIPOTESIS
# H0) Los errores son normales
# H1) Los errores NO son normales


shapiro.test(datos$t_i) #No rechazo H0) p-value = 0.2278
tseries::jarque.bera.test(datos$t_i) #No Rechazo H0) p-value = 0.7418
ks.test(datos$t_i, 'pnorm') #No Rechazo H0) 0.7212

ggplot(qq, aes(x = empiricos, y=..density..)) +
  geom_histogram(breaks = seq(-3, 3, 1), col = 'white') +
  xlab('Residuos studentizados')

###Supuestos de ANCOVA

## Supuesto de correlación

with(datos,cor(Peso_gr,Altura_cm))
# Correlacion debil de 0.19


crPlot(mod5, variable = 'log(Altura_cm)', pch = 16)

# Supuesto igualdad de pendientes
mod6 <- lm(Peso_gr~ Altura_cm + Especie + Altura_cm:Especie, data = datos)

#H0) b1 = b2 = ... = bJ
#H1) No H0)

anova(mod5, mod6) #Rechazo H0)

# Supuesto la covariable NO afecta la media de cada especie
anova(lm(Altura_cm ~ Especie, data = datos))

#p-valor : < 2.2e-16
# Rechazo el supuesto de que la covariable Altura NO afecta la medida de cada especie



ggplot(datos, aes(x = Peso_gr, y = Altura_cm, col = Especie)) +
  geom_point() +
  xlab('Peso') + 
  ylab('Altura') +
  theme_bw()+
  geom_smooth(method = 'lm', se =FALSE)

#Aquí vemos rectas lineales, con distintas pendientes y dispersión concentrada en las rectas de regresión lineal en varios casos.
# Altura Podría ser una buena covariable para el peso de los peces




```










Parece coexistir 7 pendientes 

El modelo  1 seria el siguiente: 
$$Peso_i = \beta_0\ +\  \beta_1log(Altura_i) \ +\epsilon_{i}$$
mientras que el modelo 2 queda especificado como:

$$Peso_i = \beta_0\ +\ \beta_1log(Altura_i)\ +\ \beta_2Especie_i\ +\ \epsilon_i$$

```{r}
mod0 = lm(log(Peso_gr) ~ log(Altura_cm), data = datos)
mod1 = lm(log(Peso_gr) ~ + Especie + log(Altura_cm) , data = datos)


anova(mod0, mod1)

```
Nos quedamos con el segundo modelo y nos planteamos la siguiente prueba de hipotesis. 
Ho) la pendiente de la  Altura es igual para las especies
H1) Al menos una especie tiene un valor de la pendiente distinta a las demas.

```
Podemos observar que efectivamente hay un efecto especie  sobre la constante

Nos quedamos con el segundo modelo y nos planteamos la siguiente prueba de hipotesis. 
Ho) la pendiente de la log(Altura)    es igual para las tres especies
H1) Al menos una especie tiene un valor de la pendiente distinta a las demas.
 
 Para ver si existe un efecto Especie sobre la pendiente, debemos plantearnos un modelo con interaccion.
El modelo con interaccion queda definido como:


$$Peso_i = \beta_0\ +\ \beta_1log(Altura_i)\ +\ \beta_2log(Altura_i):Especie_i\ +\ \epsilon_i$$
```{r}

mod2.0 <- lm(log(Peso_gr) ~ Especie + log(Altura_cm) + log(Altura_cm):Especie, data = datos)

mod3 <- lm((Peso_gr) ~ Especie , data = datos)

summary(mod2.0)

anova(mod1, mod2.0)


summary(mod2.0)


```





```{r, eval=FALSE}

library(emmeans)

pendientes <- emtrends(mod2.0, pairwise ~ Especie, var = 'log(Altura_cm)') ## no corre 

pendientes <- emtrends(mod0, pairwise ~ Especie, var = 'log(Altura_cm)') ## no corre 


emmeans(mod3, ~ Especie)

summary(mod0)

```
## Cross-Validation 

```{r}
set.seed(84735)

cross= prediction_summary_cv(model = modelo,  data = datos, k =10 )

glm.fit <- glm(modelo, data=datos)

cv.err.kfold <- cv.glm(data=datos, glmfit=glm.fit, K=10)
cv.err.kfold$delta[1]
 ## hacer lo mismo para los otros 2 modelos y comparar... ver la fundamentacion
## loo()


```

