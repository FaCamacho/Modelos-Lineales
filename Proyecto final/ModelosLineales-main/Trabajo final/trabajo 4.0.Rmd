---
title: "Untitled"
output: html_document
date: "2024-06-25"
---

---
title: "Trabajo final"
author: "matias"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}

library(tidyverse)
library(readxl)
library(here)
library(mixlm)
library(gridExtra)
library(car)
library(skedastic)
library(qqplotr)
library(tseries)
library(emmeans)
library(boot) 
library(kableExtra)





```

## Metodologia e introduccion 

El objetivo de este trabajo es implementar las tecnicas de analisis  estudiadas en el curso de Modelos Lineales, en partiuclar, el modelo de regresion multiple.

En una primera instancia, se procede a hacer un analisis explotatorio de los datos. 
Luego pasamos a una primera etapa de diagnostico, donde  se procede a estudiar  el supuesto de la multicolinealidad aproximiada, en el cual nos sirve para quedarnos con las variables explicativas siguiendo el criterio de Vif<5.

En la siguiente etapa, seleccionamos 3 posibles modelos, luego estudiamos el supuesto de homoscedasticidad en los residuos como tambien el test de normalidad 

En una tercera instancia, se hizo un analisis ANOVA y ANCOVA. 

Para finalizar, se usaron tecnicas como cross validation y leave-one-out para evalular los 3 modelos. 




## Descripcion de la base

Para este informe se trabajo con una base de peces. La misma consta con 158 observaciones de peces y con las siguientes variables:

La base de datos contiene información respecto de las siguientes variables:
\begin{itemize}
  \item Especie: Nombre de la especie del pescado
  \item Peso_gr: Peso del pescado en gramos
  \item LLongitud1: Longitud vertical en centímetros
  \item Longitud2: Longitud diagonal en centímetros
  \item Longitud3: Longitud transversal en centímetros
  \item Altura_cm: Altura en centímetros
  \item Ancho_cm: Ancho diagonal en centímetros
\end{itemize}

A efectos de tener un primer acercamiento con la estructura de los datos, se obtienen algunas estadisticas descripitvas, como la correlacion entre las variables cuantitativas   y un diagrama de caja para visualizar el peso en relacion a cada especie 


```{r}
#Cargar los datos
colores <- c("#003f5c", "#7a5195", "#ef5675", "#ffa600")

datos = biometria_peces


```

## Aalisis exploratorio de los datos

```{r}


str(datos)

summary(datos)

datos = datos %>%  mutate(Peso_gr = as.numeric(Peso_gr),Especie = as.factor(Especie) ) 


str(datos)

summary(datos) #Hay un pez con peso 0 gr


datos <- datos %>% filter(.,Peso_gr > 0)

summary(datos) #Deberíamos quitar el de 5.9 gr

#datos <- datos %>% filter(.,Peso_gr > 5.9)

summary(datos)

cuanti = datos %>%  select(2:7) 


matriz_correlacion <- cor(cuanti) 

 p =ggcorrplot::ggcorrplot(
        matriz_correlacion,
        method = "circle", 
        type = "upper",
        outline.col = "black",
        ggtheme = ggplot2::theme_gray,
        legend.title = "Correlacion",
        colors = c(tail(colores, 1), "#ffffff", colores[1])
      ) + 
      guides(
        fill = guide_colorbar(barheight = grid::unit(0.75, "npc"))
      )
 
 p


```


#Análisis gráfico


```{r}


longitud <- ggplot(datos, aes(x = log(Longitud1), y = log(Peso_gr))) + 
  geom_point(alpha=0.5,size=2)+
  theme_bw() +
  xlab('Longitud') +
  ylab('Peso')


ancho <- ggplot(datos, aes(x = log(Ancho_cm), y = log(Peso_gr))) + 
  geom_point(alpha=0.5,size=2)+
  theme_bw() +
  xlab('Ancho') +
  ylab('Peso')

altura <- ggplot(datos, aes(x = log(Altura_cm), y = log(Peso_gr))) + 
  geom_point(alpha=0.5,size=2)+
  theme_bw() +
  xlab('Alto') +
  ylab('Peso')

longitud_especie <- ggplot(datos, aes(x = log(Longitud1), y = log(Peso_gr), color=Especie)) + 
  geom_point(alpha=0.5,size=2)+
  theme_bw() +
  xlab('Longitud') +
  ylab('Peso')


ancho_especie <- ggplot(datos, aes(x = log(Ancho_cm), y = log(Peso_gr), color=Especie)) + 
  geom_point(alpha=0.5,size=2)+
  theme_bw() +
  xlab('Ancho') +
  ylab('Peso')

altura_especie <- ggplot(datos, aes(x = log(Altura_cm), y = log(Peso_gr), color=Especie)) + 
  geom_point(alpha=0.5,size=2)+
  theme_bw() +
  xlab('Alto') +
  ylab('Peso')


grid.arrange(longitud_especie
             ,ancho_especie
             ,altura_especie,
             ncol=1,nrow=3)

```


## Análisis de supuestos sobre modelos lineales
#Multicolinealidad
```{r}

#Analizando multicolinealidad


vif(lm(Peso_gr~ .-Especie, data = datos))


#Quitando Long2

vif(lm(Peso_gr~ .-Especie-Longitud2, data = datos))

#Quitando Long3

vif(lm(Peso_gr~ .-Especie-Longitud2-Longitud3, data = datos))

#Variables seleccionadas -> "Longitud1" , "Altura_cm" , "Ancho_cm"



```

##Modelos



## Modelo 1 

Como ya se menciono,el primer modelo estimado consiste en la regresion de la variable peso con las variables explicativas que fueron seleccionadas en el paso de multicolinealidad.
El modelo queda esepecificado como:

$$peso_{i}=  \beta_0 +\ \beta_1Longitud1_{i} + \beta_2Altura_{i}\ +\beta_3Ancho_{i}\ +\ \epsilon_{i}$$


```{r}


modelo <- lm(Peso_gr~ Longitud1+Altura_cm+Ancho_cm, data = datos)

summary(modelo) #Podríamos quitar esto ya que hasta no cumplir los supuestos la interpretación del summary no aporta

```




## Significacion individual

Para cada uno de las variables explicativas se realiza la siguiente prueba de hipotesis:

$$H_0) B_{i} = 0\ vs\ H_1) B_{i} \neq 0$$

Con region critica:  (poner la region critica)


poner el estadistico t 


Siguiendo el criterio del p_valor, la evidencia empirica sugiere que las variables  Longitud1 y Altura en centimetros son individualmente significativas para explicar el peos del pez a un nivel del5%.



## Signficacion global del modelo

Siguiendo el criterio del p_valor, a un nivel del 5%, la evidencia empirica sugiere que el modelo es globalmente significativo. Esto implica que, dada la evidencia empirica con la que se cuenta, no es posible rechazar la hipotesis de que las variables explicativas usadas no contribuyen a explicar el peso del pez.


## Diagnostico del modelo

##Homoscedasticidad 

En una primera instancia, se opto por recurrir  a un analisis visual de los residuos externamente estudientizados del modelo. 
A continuacion vemos el grafico de los residuos en el eje de las ordenadas 
Con un $\alpha=0.05$ rechazamos la hipotesis nula, por lo que podemos afirmar que no hay homoscedasticidad.


```{r}
datos$r_i <- residuals(modelo)  

# residuos

datos$t_i <- rstudent(modelo) #studentizados EXTERNAMENTE 

datos$pred <- fitted(modelo)

# H0) E(eps^2_i) = sigma^2
# H1) E(eps^2_i) = sigma^2 * h(X_1, X_2, ..., X_k)



breusch_pagan(modelo) # Rechazo H0) con p-valor del 5%


x0 = ggplot(datos, aes(x = pred, y = t_i)) + 
  geom_point(color = "red",alpha=0.5,size=1)+
  xlab('Predichos') +
  ylab('Residuos') +
 geom_abline(slope=0, intercept=c(-1,1), linetype="dashed",color="blue")+
  geom_abline(slope = 0, intercept = 0,color="blue")   +theme_bw()




grafico = function(variable) {
  ggplot(datos,aes(x=.data[[variable]],y=.data[["t_i"]])) +
    geom_point(alpha=0.5,size=1,color = "red") +
  
    labs(x = variable, y = "t_i") + 
 geom_abline(slope=0, intercept=c(-1,1), linetype="dashed",color="blue") +  geom_abline(slope = 0, intercept = 0,color="blue")   +theme_bw()
}




x1=grafico("Longitud1")
x4=grafico("Altura_cm")
x5= grafico("Ancho_cm")


grid.arrange(x0,x1,x4,x5,ncol=2,nrow=2)

#grid.arrange(crPlot(modelo,"Longitud1"),crPlot(modelo,"Altura_cm"),crPlot(modelo,"Ancho_cm"),ncol=3,nrow=1)





```
## Normalidad 

El histograma  de los residuos estandarizados parece no parecerse a  una distribucion  normal en los residuos.
Ademas, los test de normalidad de Shapiro-Wilk y Jarque-Bera, segun el criterio del p_valor y para un $\alpha=0.5$ se rechaza la hipotesis nula de normalidad de los residuos.

```{r}
n <- nrow(datos)

z_i <- qnorm(seq(n)/(n + 1))

qq <- data.frame(teoricos = z_i,empiricos = sort(datos$t_i))




# PRUEBA DE HIPOTESIS
# H0) Los errores son normales
# H1) Los errores NO son normales


shapiro.test(datos$t_i) #Rechazo H0) con un alpha al 5%
tseries::jarque.bera.test(datos$t_i) #Rechazo H0) con un p-valor de 5%


ggplot(qq, aes(x = empiricos, y=..density..)) +
  geom_histogram(bins=10) +  
      theme(axis.title.y=element_blank(),
            axis.ticks.x=element_blank(),
            axis.ticks.y=element_blank(),
            axis.title.x=element_text(face="bold", size=12),
            plot.title=element_text(size=16, face="bold", hjust=0.5)) +
  xlab('Residuos studentizados')
```

## Modelo 2 



```{r}
modelo_ajustado <- lm(log(Peso_gr) ~ (Longitud1)+(Altura_cm)+(Ancho_cm), data = datos)

```



## modelo 3 

```{r}
modelo_ajustado2 <- lm(log(Peso_gr) ~ log(Longitud1)+log(Altura_cm)+log(Ancho_cm), data = datos)

```







## Homoscedasticidad de "Modelo_ajustado2"

```{r}

datos$r_i <- residuals(modelo_ajustado2)  

# residuos

datos$t_i <- rstudent(modelo_ajustado2) #studentizados EXTERNAMENTE 

datos$pred <- fitted(modelo_ajustado2)

# H0) E(eps^2_i) = sigma^2
# H1) E(eps^2_i) = sigma^2 * h(X_1, X_2, ..., X_k)



breusch_pagan(modelo_ajustado2) #No Rechazo H0) con p-valor de 0.73


ggplot(datos, aes(x = pred, y = t_i)) + 
  geom_point(color = "red",alpha=0.5,size=1)+
  xlab('Predichos') +
  ylab('Residuos') +
 geom_abline(slope=0, intercept=c(-1,1), linetype="dashed",color="blue")+
  geom_abline(slope = 0, intercept = 0,color="blue")   +theme_bw()



#grid.arrange(crPlot(modelo,"Longitud1"),crPlot(modelo,"Altura_cm"),crPlot(modelo,"Ancho_cm"),ncol=3,nrow=1)






```

##Normalidad

```{r}

n <- nrow(datos)

z_i <- qnorm(seq(n)/(n + 1))

qq <- data.frame(teoricos = z_i,empiricos = sort(datos$t_i))

ggplot(qq, aes(x = teoricos, y = empiricos)) +
  geom_point() +
  xlab('Cuantiles teoricos') +
  ylab('Cuantiles empiricos') +
  geom_abline(slope = 1, intercept = 0, col = 2, size = 1.5)


# PRUEBA DE HIPOTESIS
# H0) Los errores son normales
# H1) Los errores NO son normales


shapiro.test(datos$t_i) #Rechazo H0) con un p-valor de 0.0049
tseries::jarque.bera.test(datos$t_i) #Rechazo H0) con un p-valor de 1.794e-05
ks.test(datos$t_i, 'pnorm') #No Rechazo H0) con un p-valor de 0.5317

ggplot(qq, aes(x = empiricos, y=..density..)) +
  geom_histogram(breaks = seq(-3, 3, 1), col = 'white') +
  xlab('Residuos studentizados')
```



## Atípicos

```{r}
##afuera?

h_i <- influence(modelo_ajustado2)$hat
D_i <- cooks.distance(modelo_ajustado2)
df <- data.frame(i = 1:nrow(datos),
                 h_i = h_i,
                 D_i = D_i)

# Distancia de Cook
ggplot(df, aes(x = i, y = D_i)) +
  geom_point() +
  geom_segment(aes(x = i, xend = i, y = 0, yend = D_i)) +
  xlab('') +
  ylab(expression(D[i])) +
  geom_abline(slope = 0, intercept = 4/50, col = 2, linetype = 'dashed')

#hay algún atípico 

```


#evaluacion de modelo 

```{r}


 bic1 = BIC(modelo)
bic2= BIC(modelo_ajustado)
bic3 = BIC(modelo_ajustado2)
aic1 = AIC(modelo)
aic2=AIC(modelo_ajustado)
aic3= AIC(modelo_ajustado2)

summary(modelo)$adj.r.squared

summary(modelo_ajustado)$adj.r.squared

summary(modelo_ajustado2)$adj.r.squared




```
## ANOVA a 1 vía

El objetivo es estudiar si existe igualdad de medias para la variable categorica 'Especie'. 
Haciendo el analisis de varianza a una via, nos plantemos 2 modelos, uno solo con la constante y otro especificando la especie.

El modelo con la constante queda especificado de la siguiente manera: 

$$Peso_{ij} = \mu + \epsilon_{ij}$$
mieintras que si le agregamos el efecto especie queda:

$$Peso_{ij} = \mu + Especie_{ij} +  \epsilon_{ij}$$

Se puede observar tambien mediante un grafico de puntos que existe una relacion lineal entre el peso y la longitud.  Mas aun haciendo una transformacion logaritmica  a ambas variables.

A un nivel de significacion del 5%, podemos afirmar que  tenemos  evidencia suficiente para  rechaza la hipotesis nula de igualdad de medias. 

Al plantearnos el modelo con la covariable longitud1, podemos ver que  para predecir el peso  existe  ademas de un efecto especie un efecto longitud. 










```{r}


datos_especie <- datos %>%
  group_by(Especie) %>%
  summarise("media(peso)" = round(mean(Peso_gr),2),
            "desvio(peso)" = round(sd(Peso_gr),2),
            "min(peso)"=round(min(Peso_gr),2),
            "max(peso)"=round(max(Peso_gr),2))


ggplot(datos,aes(x=Especie,y=Peso_gr,fill=Especie)) + geom_boxplot() +xlab('Peso') + 
  ylab('Longitud')



## se nota mas la linealidad en los regresores con  la transformacion logaritmica aplciada 

ggplot(datos, aes(x =log(Longitud1) ,y=log(Peso_gr), col = Especie)) +
  geom_point(alpha = 0.5, size = 2) +
  xlab('Peso') + 
  ylab('Longitud') +  scale_color_brewer(palette="Dark2") + 
  theme_bw()

## creo que anova(mod1.0) se encarga de comparar ya de por si el modelo de grupos con la que tiene solo la cte.
mod1.1 <- lm(log(Peso_gr) ~ 1, data = datos) #Modelo con "Peso ~ 1"

mod1.0<- lm(log(Peso_gr) ~ Especie, data = datos)   #Modelo con "Peso ~ Especie"



mod1.2 <- lm(log(Peso_gr) ~ Especie + log(Longitud1) , data = datos)



Anova(mod1.2)

## tenemos la significacion de la covariable ajustnado por el efecto especie. 
## y la significacion de la covariable ajustando por el efecto longitud 

# hay un efecto especie como se vio anteriormente. 




# summary(mod1.0)

#anova(mod0, mod1)

#H0) m1 = m2 = ... = mJ
#H1) No H0)

#p-value: 2.2e-16 de la prueba de significación global
# Rechazamos H0) y afirmamos que la especie es relevante para determinar el peso de un pez





summary(lm((Peso_gr) ~ Especie + 0, data = datos))


#Vemos que para algunos peces la especie es relevante para determinar el peso mientras que para otras no
#Por ejemplo, para los Bream estamos en el primer caso mientras que para los Smelt en el segundo




ggplot(datos, aes(x =log(Longitud1) ,y=log(Peso_gr), col = Especie)) +
  geom_point() +
  xlab('Peso') + 
  ylab('Longitud') +
  theme_bw()



```


```{r}
# residuos

datos$t_i <- rstudent(mod1.0) #studentizados EXTERNAMENTE 

datos$pred <- fitted(mod1.0)

ggplot(datos, aes(x = pred, y = t_i)) + 
  geom_point(color = "red",alpha=0.5,size=1)+
  xlab('Predichos') +
  ylab('Residuos') +
 geom_abline(slope=0, intercept=c(-1,1), linetype="dashed",color="blue")+
  geom_abline(slope = 0, intercept = 0,color="blue")   +theme_bw()



# H0) E(eps^2_i) = sigma^2
# H1) E(eps^2_i) = sigma^2 * h(X_1, X_2, ..., X_k)

breusch_pagan(mod1.0) #No Rechazo H0) con p-valor 0.92

# Normalidad

n <- nrow(datos)

z_i <- qnorm(seq(n)/(n + 1))

qq <- data.frame(teoricos = z_i,empiricos = sort(datos$t_i))

ggplot(qq, aes(x = teoricos, y = empiricos)) +
  geom_point() +
  xlab('Cuantiles teoricos') +
  ylab('Cuantiles empiricos') +
  geom_abline(slope = 1, intercept = 0, col = 2, size = 1.5)


# PRUEBA DE HIPOTESIS
# H0) Los errores son normales
# H1) Los errores NO son normales


shapiro.test(datos$t_i) #Rechazo H0) con p-value = 0.001005
tseries::jarque.bera.test(datos$t_i) #Rechazo H0) con p-value = 4.169e-09
ks.test(datos$t_i, 'pnorm') #No Rechazo H0) con p-value = 0.8776

ggplot(qq, aes(x = empiricos, y=..density..)) +
  geom_histogram(breaks = seq(-3, 3, 1), col = 'white') +
  xlab('Residuos studentizados')



###Supuestos de ANCOVA

## Supuesto de correlación

with(datos,cor(Peso_gr,Longitud1))
# Correlacion fuerte de 0.92


crPlot(mod1, variable = 'log(Longitud1)', pch = 16)

# Supuesto igualdad de pendientes
mod2 <- lm(log(Peso_gr)~ log(Longitud1) + Especie + log(Longitud1):Especie, data = datos)



mod2.1 <- lm(log(Peso_gr)~ log(Longitud1) + Especie , data = datos)  #Este es el modelo posta posta posta posta

summary(mod2)

#H0) b1 = b2 = ... = bJ
#H1) No H0)

anova(mod2.1, mod2) #No Rechazo H0) Las pendientes son iguales

# Supuesto la covariable NO afecta la media de cada especie
anova(lm(log(Longitud1) ~ Especie, data = datos))

#p-valor : < 2.2e-16
# Rechazo el supuesto de que la covariable NO afecta la medida de cada especie



ggplot(datos, aes(x = log(Peso_gr), y = log(Longitud1), col = Especie)) +
  geom_point() +
  xlab('Peso') + 
  ylab('Longitud') +
  theme_bw()+
  geom_smooth(method = 'lm', se =FALSE)

#Aquí vemos rectas notoriamente lineales, con las mismas pendientes y dispersión en torno a las rectas de regresión lineal

#Concluimos que la longitud como covariable no altera la capacidad explicativa de la especie.





```



## Ancova 
\Para ver si existe un efecto Especie sobre la pendiente, debemos plantearnos un modelo con interaccion.
El modelo con interaccion queda definido como:


$$Peso_i = \beta_0\ +\ \beta_1log(Longitud_i)\ +\ \beta_2log(Longitud1_i):Especie_i\ +\ \epsilon_i$$

Ahora pasamos a estudiar si  efectivamente existe igualdad de pendientes entre las especies.
 No hay evidencia suficiente para decir que la pendiente sean  distinta entre las especies. 

 
 

```{r}

#Modelo con Covariable Longitud


 
mod2.0 <- lm(log(Peso_gr) ~ log(Longitud1)+Especie +   log(Longitud1):Especie, data = datos)

anova(mod2.1,mod2.0)
#mod1.2 <- lm(log(Peso_gr) ~ log(Longitud1) + Especie, data = datos)

###Supuestos de linealidad

#Homosedasticidad

datos$r_i <- residuals(mod1.2)  

datos$pred <- fitted(mod1.2)

breusch_pagan(mod1.2) 


ggplot(datos, aes(x = pred, y = t_i)) + 
  geom_point(color = "red",alpha=0.5,size=1)+
  xlab('Predichos') +
  ylab('Residuos') +
 geom_abline(slope=0, intercept=c(-1,1), linetype="dashed",color="blue")+
  geom_abline(slope = 0, intercept = 0,color="blue")   +theme_bw()




ggplot(datos, aes(x =log(Longitud1), y = log(Peso_gr), color=Especie)) + 
  geom_point(alpha=0.5,size=2)+
  xlab('Longitud') +
  ylab('Peso')
```





```{r}

#Modelo con Covariable ANCHO
##AFUERA 
mod3 <- lm(log(Peso_gr) ~ log(Ancho_cm) + Especie  , data = datos)

###Supuestos de modelos lineales

#Linealidad

with(datos,cor(Peso_gr,Ancho_cm)) #Correlacion debil de 0.14

#plot(log(datos$Peso_gr), log(datos$Ancho_cm))


ggplot(datos, aes(x=log(Ancho_cm), y = log(Peso_gr))) + geom_point(size=2, alpha=0.5) + theme_bw()


#plot(lm(lm(log(Peso_gr) ~ log(Ancho_cm)  , data = datos)))

# plot(lm(lm(log(Peso_gr) ~ log(Ancho_cm)  , data = datos)))


#Homosedasticidad

datos$r_i <- residuals(mod3)  

# residuos

datos$t_i <- rstudent(mod3) #studentizados EXTERNAMENTE 

datos$pred <- fitted(mod3)

# H0) E(eps^2_i) = sigma^2
# H1) E(eps^2_i) = sigma^2 * h(X_1, X_2, ..., X_k)

breusch_pagan(mod3) #Rechazo H0) con p-valor 0.0001425355

# Normalidad

n <- nrow(datos)

z_i <- qnorm(seq(n)/(n + 1))

qq <- data.frame(teoricos = z_i,empiricos = sort(datos$t_i))

ggplot(qq, aes(x = teoricos, y = empiricos)) +
  geom_point() +
  xlab('Cuantiles teoricos') +
  ylab('Cuantiles empiricos') +
  geom_abline(slope = 1, intercept = 0, col = 2, size = 1.5)


# PRUEBA DE HIPOTESIS
# H0) Los errores son normales
# H1) Los errores NO son normales


shapiro.test(datos$t_i) #No echazo H0) p-value = 0.5116
tseries::jarque.bera.test(datos$t_i) #No Rechazo H0) p-value = 0.916
ks.test(datos$t_i, 'pnorm') #No Rechazo H0) 0.8489

ggplot(qq, aes(x = empiricos, y=..density..)) +
  geom_histogram(breaks = seq(-3, 3, 1), col = 'white') +
  xlab('Residuos studentizados')

###Supuestos de ANCOVA

## Supuesto de correlación

with(datos,cor(Peso_gr,Ancho_cm))
# Correlacion debil de 0.14


crPlot(mod3, variable = 'log(Ancho_cm)', pch = 16)

# Supuesto igualdad de pendientes
mod4 <- lm(Peso_gr~ Ancho_cm + Especie + Ancho_cm:Especie, data = datos)

#H0) b1 = b2 = ... = bJ
#H1) No H0)

anova(mod3, mod4) #Rechazo H0)

# Supuesto la covariable NO afecta la media de cada especie
anova(lm(Ancho_cm ~ Especie, data = datos))

#p-valor : < 2.2e-16
# Rechazo el supuesto de que la covariable Ancho NO afecta la medida de cada especie



ggplot(datos, aes(x = Peso_gr, y = Ancho_cm, col = Especie)) +
  geom_point() +
  xlab('Peso') + 
  ylab('Ancho') +
  theme_bw()+
  geom_smooth(method = 'lm', se =FALSE)

#Aquí vemos rectas lineales, con distintas pendientes y dispersión alejada de las rectas de regresión lineal en varios casos




```



```{r}

#Modelo con Covariable ALTURA

mod5 <- lm(log(Peso_gr) ~ log(Altura_cm) + Especie  , data = datos)

###Supuestos de modelos lineales

#Linealidad

with(datos,cor(Peso_gr,Altura_cm)) #Correlacion debil de 0.19

plot(log(datos$Peso_gr), log(datos$Altura_cm))


#Homosedasticidad

datos$r_i <- residuals(mod5)  

# residuos

datos$t_i <- rstudent(mod5) #studentizados EXTERNAMENTE 

datos$pred <- fitted(mod5)

# H0) E(eps^2_i) = sigma^2
# H1) E(eps^2_i) = sigma^2 * h(X_1, X_2, ..., X_k)

breusch_pagan(mod5) #Rechazo H0) con p-valor 3.463588e-05

# Normalidad

n <- nrow(datos)

z_i <- qnorm(seq(n)/(n + 1))

qq <- data.frame(teoricos = z_i,empiricos = sort(datos$t_i))

ggplot(qq, aes(x = teoricos, y = empiricos)) +
  geom_point() +
  xlab('Cuantiles teoricos') +
  ylab('Cuantiles empiricos') +
  geom_abline(slope = 1, intercept = 0, col = 2, size = 1.5)


# PRUEBA DE HIPOTESIS
# H0) Los errores son normales
# H1) Los errores NO son normales


shapiro.test(datos$t_i) #No rechazo H0) p-value = 0.2278
tseries::jarque.bera.test(datos$t_i) #No Rechazo H0) p-value = 0.7418
ks.test(datos$t_i, 'pnorm') #No Rechazo H0) 0.7212

ggplot(qq, aes(x = empiricos, y=..density..)) +
  geom_histogram(breaks = seq(-3, 3, 1), col = 'white') +
  xlab('Residuos studentizados')

###Supuestos de ANCOVA

## Supuesto de correlación

with(datos,cor(Peso_gr,Altura_cm))
# Correlacion debil de 0.19


crPlot(mod5, variable = 'log(Altura_cm)', pch = 16)

# Supuesto igualdad de pendientes
mod6 <- lm(Peso_gr~ Altura_cm + Especie + Altura_cm:Especie, data = datos)

#H0) b1 = b2 = ... = bJ
#H1) No H0)

anova(mod5, mod6) #Rechazo H0)

# Supuesto la covariable NO afecta la media de cada especie
anova(lm(Altura_cm ~ Especie, data = datos))

#p-valor : < 2.2e-16
# Rechazo el supuesto de que la covariable Altura NO afecta la medida de cada especie



ggplot(datos, aes(x = Altura_cm, y =Peso_gr, col = Especie)) +
  geom_point() +
  xlab('Peso') + 
  ylab('Altura') +
  theme_bw()+
  geom_smooth(method = 'lm', se =FALSE)

#Aquí vemos rectas lineales, con distintas pendientes y dispersión concentrada en las rectas de regresión lineal en varios casos.
# Altura Podría ser una buena covariable para el peso de los peces




```










Parece coexistir 7 pendientes 

El modelo  1 seria el siguiente: 
$$Peso_i = \beta_0\ +\  \beta_1log(Altura_i) \ +\epsilon_{i}$$
mientras que el modelo 2 queda especificado como:

$$Peso_i = \beta_0\ +\ \beta_1log(Altura_i)\ +\ \beta_2Especie_i\ +\ \epsilon_i$$

```{r}
mod0 = lm(log(Peso_gr) ~ log(Altura_cm), data = datos)
mod1 = lm(log(Peso_gr) ~ + Especie + log(Altura_cm) , data = datos)


anova(mod0, mod1)

```


```{r} 
##AFUERA 

mod2.0 <- lm(log(Peso_gr) ~ Especie + log(Altura_cm) + log(Altura_cm):Especie, data = datos)



summary(mod2.0)

anova(mod5, mod2.0)





```





```{r, eval=FALSE}

## sacar 
library(emmeans)

pendientes <- emtrends(mod2.0, pairwise ~ Especie, var = 'log(Altura_cm)') ## no corre 

pendientes <- emtrends(mod5, pairwise ~ Especie, var = 'log(Altura_cm)') ## no corre 


emmeans(mod3, ~ Especie)

summary(mod0)

```
## Cross-Validation 

El objetivo de la validacion cruzada es separar primero la base en 2, una de testeo  y otra de entrenamiento. Luego se usa esta ultima para estimar el modelo. Luego se utiliza el modelo para predecir la variable peso en la base de testeo. Por ultimo se calcula el ECM de dichas predicciones

$$CV_{[n]}= \frac{1}{k}\sum_{i=1}^kECM_{i}$$


```{r}
set.seed(84735)


glm.fit <- glm(mod1.1, data=datos) ## solo la constante ~ 1 

cv.err.kfold <- cv.glm(data=datos, glmfit=glm.fit, K=10) #Solo con la constante
k1 = round(cv.err.kfold$delta[1],2)


glm.fit2 = glm(mod1.0, data = datos)

cv.err.kfold2 <- cv.glm(data=datos, glmfit=glm.fit2, K=10) #Con especie
k2 = round(cv.err.kfold2$delta[1],2)
?cv.glm
glm.fit3 <- glm(mod2.1, data=datos)
cv.err.kfold3 <- cv.glm(data=datos, glmfit=glm.fit3, K=10) #Con todo ( es decir con la covariable longitud1 y especie)
k3=round(cv.err.kfold3$delta[1],2)

df = data.frame(modelo = c("modelo 1", "modelo 2","modelo 3"), k_folds_cv = c(k1,k2,k3))


df %>%  kable() %>%   kable_styling(font_size = 8, full_width = FALSE, latex_options = "HOLD_position") %>% 
    kable_classic_2()






#Predicción:


n=nrow(datos)
#Leave one out

## se rompe todo 
prod<-rep(NA,n)

for(i in 1:n){
  
  datos_i <- datos[-i,]
  mod_i <- update(modelo, data= datos_i)
  pred[i]<- (predict(mod_i,newdata=datos[i,])$prod)
}









```